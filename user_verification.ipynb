{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "user_verification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMwKeVftalqhEMKAuIQiSwF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/basolu/Basolu-Machine-Learning/blob/main/user_verification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD2-JHXB6CVM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "outputId": "073940cb-ea0c-420a-dc14-1a9f376c61bf"
      },
      "source": [
        "import tensorflow as tf\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import model_from_json\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.layers import Input, Dropout, Dense, LSTM, TimeDistributed, RepeatVector\n",
        "from numpy import save\n",
        "from math import*\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from scipy.interpolate import CubicSpline      # for warping\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import collections\n",
        "\n",
        "action = int(input(\"Run training (yes-1 \\ no-0)?\"))\n",
        "\n",
        "def DA_Jitter(X, sigma=0.05):\n",
        "    myNoise = np.random.normal(loc=0, scale=sigma, size=X.shape)\n",
        "    return X+myNoise\n",
        "\n",
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values\n",
        "\n",
        "# load a list of files and return as a 3d numpy array\n",
        "def load_group(filenames, prefix=''):\n",
        "\tloaded = list()\n",
        "\tfor name in filenames:\n",
        "\t\tdata = load_file(prefix + name)\n",
        "\t\tloaded.append(data)\n",
        "\t# stack group so that features are the 3rd dimension\n",
        "\tloaded = dstack(loaded)\n",
        "\treturn loaded\n",
        "\n",
        "# load a dataset group, such as train or test\n",
        "def load_dataset_group(group, prefix=''):\n",
        "  filepath = prefix + group + '/Inertial Signals/'\n",
        "  # load all 6 files as a single array\n",
        "  filenames = list()\n",
        "  # total acceleration\n",
        "  filenames += [group+'_acc_x.txt', group+'_acc_y.txt', group+'_acc_z.txt']\n",
        "  # body acceleration\n",
        "  filenames += [group+'_gyr_x.txt', group+'_gyr_y.txt', group+'_gyr_z.txt']\n",
        "  # load input data\n",
        "  X = load_group(filenames, filepath)\n",
        "  # load class output\n",
        "  y = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "  return X, y\n",
        "\n",
        "# load the dataset, returns train and test X and y elements\n",
        "def load_dataset(prefix=''):\n",
        "  # load all train\n",
        "  trainX, trainy = load_dataset_group('train', prefix + 'drive/MyDrive/Dataset_2/')\n",
        "  #print(\"Shape trainX and trainy:\", trainX.shape, trainy.shape)\n",
        "  # load all test\n",
        "  testX, testy = load_dataset_group('test', prefix + 'drive/MyDrive/Dataset_2/')\n",
        "  subjects = read_csv('drive/MyDrive/Dataset_2/train/y_train.txt', header=None, delim_whitespace=True)\n",
        "  # zero-offset class values\n",
        "  trainy = trainy - 1\n",
        "  testy = testy - 1\n",
        "  # one hot encode y\n",
        "  trainy = to_categorical(trainy)\n",
        "  testy = to_categorical(testy)\n",
        "  #print(\"Shape train and test:\",trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
        "  #print(trainX.shape[1], trainX.shape[2], trainy.shape[1]) \n",
        "  return trainX, trainy, testX, testy\n",
        "\n",
        "def autoencoder_model(X):\n",
        "  trainX = X\n",
        "  model = Sequential(\n",
        "  [\n",
        "        layers.Input(shape=(trainX.shape[1], trainX.shape[2])),\n",
        "        layers.Conv1D(\n",
        "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
        "        ),\n",
        "        layers.Dropout(rate=0.2),\n",
        "        layers.Conv1D(\n",
        "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
        "        ),\n",
        "        layers.Conv1DTranspose(\n",
        "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
        "        ),\n",
        "        layers.Dropout(rate=0.2),\n",
        "        layers.Conv1DTranspose(\n",
        "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
        "        ),\n",
        "        layers.Conv1DTranspose(filters=trainX.shape[2], kernel_size=7, padding=\"same\"),\n",
        "  ]\n",
        ")\n",
        "  return model\n",
        "\n",
        "#training-set for user 3's walking\n",
        "def fun_train_test():\n",
        "  trainX, trainy, testX, testy = load_dataset()\n",
        "  subject = read_csv(\"drive/MyDrive/Dataset_2/train/y_train.txt\", header=None, delim_whitespace=True)\n",
        "  size = 0 #to determinate array's size\n",
        "  #for the training set, only target's walks (subject 3 now)\n",
        "  for i in range(0, len(subject)):\n",
        "    if (subject[0][i] == 1): \n",
        "      size += 1\n",
        "  \n",
        "  train_data = np.empty([int (size), trainX.shape[1], trainX.shape[2]])\n",
        "  number_train = 0\n",
        "  for i in range(0, len(subject)):\n",
        "    if (subject[0][i] == 1):\n",
        "      #taking only ther subject's samples\n",
        "      train_data[number_train] = trainX[i]\n",
        "      number_train += 1\n",
        "\n",
        "  print(\"Train size:\", number_train)\n",
        "  #saving sets\n",
        "  np.save('drive/MyDrive/Dataset_2/train_data.npy', train_data)\n",
        "  return train_data\n",
        "\n",
        "def run_training():\n",
        "  trainX, trainy, testX, testy = load_dataset()\n",
        "  train_data = fun_train_test()\n",
        "  train_jitter = DA_Jitter(train_data, 0.05) #augmentation\n",
        "  train_data = np.concatenate((train_data, train_jitter), axis = 0)\n",
        "  np.save('drive/MyDrive/Dataset_2/train_data.npy', train_data)\n",
        "  # np.save('drive/MyDrive/Dataset_1/test_data.npy', test_data)\n",
        "  model = autoencoder_model(train_data)\n",
        "  model.compile(optimizer='adam', loss='mae', metrics='accuracy')\n",
        "  #model.summary()\n",
        "  nb_epochs = 50\n",
        "  batch_size = 10\n",
        "  history = model.fit(train_data, train_data, epochs=nb_epochs, batch_size=batch_size, validation_split=0.05).history\n",
        "  print(\"Training completed\")\n",
        "  #save the trained model\n",
        "  model_json = model.to_json()\n",
        "  with open(\"drive/MyDrive/Dataset_2/model_target.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "  #serialize weights to HDF5\n",
        "  model.save_weights(\"drive/MyDrive/Dataset_2/model_target.h5\")\n",
        "  print(\"Saved model to disk\")\n",
        "\n",
        "def detect_anomalies():\n",
        "  trainX, trainy, test_data, testy = load_dataset()\n",
        "  train_data = np.load('drive/MyDrive/Dataset_2/train_data.npy')\n",
        "  # test_data  = np.load('drive/MyDrive/Dataset_1/test_data.npy')\n",
        "  print(\"Dataset loaded\")\n",
        "  # print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
        "  json_file = open(\"drive/MyDrive/Dataset_2/model_target.json\", \"r\")\n",
        "  loaded_model_json = json_file.read()\n",
        "  json_file.close()\n",
        "  #load model from a json model\n",
        "  model = model_from_json(loaded_model_json)\n",
        "  # load weights into new model\n",
        "  model.load_weights(\"drive/MyDrive/Dataset_2/model_target.h5\")\n",
        "  print(\"Loaded model from disk\")  \n",
        "  \n",
        "  train_data_pred = model.predict(train_data)\n",
        "  print(\"Train_data_pred shape:\", train_data_pred.shape)\n",
        "  #difference between input data and model output\n",
        "  train_mae_loss = np.mean(np.abs(train_data_pred - train_data), axis=1) \n",
        "  train_mae_loss = train_mae_loss.T #inverted the shape\n",
        "  print(\"Train_mae_loss shape:\", train_mae_loss.shape)\n",
        "  \n",
        "  shape0 = train_mae_loss.shape[0]\n",
        "  shape1 = train_mae_loss.shape[1]\n",
        "  threshold  = [0] * shape0\n",
        "  for i in range(0, shape0): #plotting the loss for each sensor (0-6)\n",
        "    plt.hist(train_mae_loss[i], bins=50)\n",
        "    plt.xlabel(\"train MAE loss\")\n",
        "    plt.ylabel(\"No of samples\")\n",
        "    # plt.show()\n",
        "    # Detect all the samples which are anomalies.\n",
        "    threshold[i] = np.max(train_mae_loss[i])\n",
        "    # print(\"Reconstruction error threshold:\", threshold[i], end = \"\\n\")\n",
        "\n",
        "  test_data_pred = model.predict(test_data)\n",
        "  print(\"Test_data_pred shape:\", test_data_pred.shape)\n",
        "  test_mae_loss = np.mean(np.abs(test_data_pred - test_data), axis=1)\n",
        "  test_mae_loss = test_mae_loss.T\n",
        "  print(\"Test_mae_loss shape:\", test_mae_loss.shape)\n",
        "  \n",
        "  shape0 = test_mae_loss.shape[0]\n",
        "  shape1 = test_mae_loss.shape[1]\n",
        "  anomalies = np.zeros((shape0,shape1))\n",
        "  print(\"Anomalies's shape:\", anomalies.shape)\n",
        "  for i in range(0, shape0): #0-6\n",
        "    plt.hist(test_mae_loss[i], bins=50)\n",
        "    plt.xlabel(\"test MAE loss\")\n",
        "    plt.ylabel(\"No of samples\") \n",
        "    # plt.show()\n",
        "    # Detect all the samples which are anomalies.\n",
        "    anomalies[i] = test_mae_loss[i] > threshold[i]\n",
        "    # print(\"Number of anomaly samples: \", np.sum(anomalies))\n",
        "    \n",
        "  print(\"Anomalies's shape\",anomalies.shape)\n",
        "\n",
        "  # Checking how the first sequence is learnt\n",
        "  plt.plot(train_data[0])\n",
        "  plt.plot(train_data_pred[0])\n",
        "  # plt.show()\n",
        "\n",
        "  # index_anomalies == 1 if it was an anomalies index\n",
        "  index_anomalies = np.zeros(shape1) \n",
        "  for i in range(0, shape1): \n",
        "    count = 0\n",
        "    for j in range(0, shape0): #0-6\n",
        "      if (anomalies[j][i] == 1): #anomalie\n",
        "        count += 1\n",
        "    if (count >= (shape0*0.3) ): #at least 30% sensor detected anomalies\n",
        "      index_anomalies[i] = 1\n",
        " \n",
        "  \n",
        "  print(\"Index_anomalies.shape:\", index_anomalies.shape)\n",
        "  print(\"Number of anomalies:\", np.count_nonzero(index_anomalies))\n",
        "\n",
        "  if (np.sum(anomalies)): find_accuracy(index_anomalies)\n",
        "\n",
        "def find_accuracy(index_anomalies):  \n",
        "  #for each sample, the subject's id\n",
        "  test_subjects = read_csv('drive/MyDrive/Dataset_2/test/y_test.txt', header=None, delim_whitespace=True)\n",
        "  \n",
        "  if (sum(index_anomalies) != 0): #if there're anomalies  \n",
        "    true_p = 0\n",
        "    true_n = 0\n",
        "    false_p = 0\n",
        "    false_n = 0\n",
        "    j = 0\n",
        "    for i in range(0, index_anomalies.shape[0]): \n",
        "      if (test_subjects[0][i] == 1):\n",
        "        if (index_anomalies[i] == 1): #detected incorrect anomalie  \n",
        "          false_n += 1\n",
        "          j += 1 \n",
        "        else: true_p += 1 #detected no-anomalie\n",
        "      else : #no-targte's walks \n",
        "        if (index_anomalies[j] == 1): #detected anomalie\n",
        "          true_n += 1\n",
        "          j += 1\n",
        "        else: #don't detect anomalie\n",
        "          false_p += 1\n",
        "\n",
        "  print(\"False Negative:\", false_n, \"False Positive:\", false_p, \"True Negative:\", true_n, \"True Positive:\", true_p, end =\"\\n\")\n",
        "  accuratezza = (true_n + true_p)/i\n",
        "  print(\"Accuracy:\", accuratezza*100) \n",
        "\n",
        "if (action == 1):\n",
        "  run_training()\n",
        "detect_anomalies()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run training (yes-1 \\ no-0)?0\n",
            "Dataset loaded\n",
            "Loaded model from disk\n",
            "Train_data_pred shape: (4416, 128, 6)\n",
            "Train_mae_loss shape: (6, 4416)\n",
            "Test_data_pred shape: (4936, 128, 6)\n",
            "Test_mae_loss shape: (6, 4936)\n",
            "Anomalies's shape: (6, 4936)\n",
            "Anomalies's shape (6, 4936)\n",
            "Index_anomalies.shape: (4936,)\n",
            "Number of anomalies: 4177\n",
            "False Negative: 0 False Positive: 4686 True Negative: 4 True Positive: 246\n",
            "Accuracy: 5.065856129685916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmKIxB2l_eJX"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}